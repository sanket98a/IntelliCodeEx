

<div style='text-align: center; margin-bottom: 5px;'>
    <h2 style='font-size: 500px; font-family: Courier New, monospace;
                    letter-spacing: 2px; text-decoration: none;'>
    <span style='margin-left: -20px;background: linear-gradient(45deg, #ed4965, #c05aaf);
                            -webkit-background-clip: text;
                            -webkit-text-fill-color: transparent;
                            text-shadow: none;'>
                    IntelliCodeEx
</span>
<span>
<sup style='position: relative; top: 5px; color: #ed4965;font-size: -100px;'>by Sanki</sup>
</span>
</h2>
</div>


IntelliCodeEx is a code explanation tool powered by LLM (Language Model) that utilizes the open-source Llama-2 7B GGML quantized model. It's designed to provide intelligent explanations for various programming languages. This project builds a Streamlit-based user interface for the proof of concept (POC). It includes a chatbot capable of explaining code in Python, C#, JavaScript, and .NET languages.

## üéâ Features
1. **Open-Source Model**: IntelliCodeEx leverages an open-source model to provide code explanations, ensuring transparency and accessibility.

2. **Quantized Model Implementation**: To optimize resource usage, the tool utilizes a quantized model, reducing memory and processing requirements.

3. **Chatbot Implementation**: An interactive chatbot is integrated into the tool, allowing users to receive code explanations through a conversational interface.

4. **Data Security**: IntelliCodeEx prioritizes data security, ensuring that sensitive information is handled with utmost care and follows best practices for secure data handling.

5. **On-Premise Solution**: The tool offers an on-premise deployment option, providing control and privacy over your code explanations within your own infrastructure.

6. **Low Cost**: It is cost-effective, offering efficient code explanations without incurring significant expenses.

7. **Easy Customizability**: IntelliCodeEx is designed to be easily customizable to adapt to specific requirements, making it a versatile solution for various use cases.
-------------------------------------------

## üèÉVariants of IntelliCodeEx

1. **Llama-2 7B GGML 4-bit Quantized Model:** This variant uses a 4-bit quantized version of the Llama-2 7B GGML model.

2. **Llama-2 7B Original Model with Self-Quantization Options:** This variant offers the original Llama-2 7B model and includes options for self-quantization.

## üíª Installation

### A. Llama-2 7B GGML 4-bit Quantized Model

1. Clone the repository:
   ```cmd
   git clone [http://xyz.com](https://github.com/sanket98a/IntelliCodeEx.git)
   ```

2. Install the required dependencies:
    ```cmd
    pip install -r requirements.txt
    ```
3. Run the following command to start the Streamlit UI:
    ```cmd
    streamlit run app.py
    ```

This will start the IntelliCodeEx chatbot and allow you to explain code in various languages.

